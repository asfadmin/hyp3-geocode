# setuptools-scm doesn't work well with a shallow clone, see:
#    https://docs.gitlab.com/ee/ci/yaml/#shallow-cloning
variables:
  GIT_DEPTH: 0

.conda_template: &before_conda_env
  - source $HOME/.bashrc
  - conda update -n base -c defaults conda
  - conda install -c conda-forge -y tox tox-conda

.before_template: &before_defaults
  - python3 -m pip install --upgrade pip
  - python3 -m pip install --upgrade setuptools wheel twine s3pypi "setuptools-scm[toml]" importlib_metadata

workflow:
  rules:
    # Don't run pipelines for tags because they will be created in the tools-bot stage
    - if: $CI_COMMIT_TAG
      when: never
    # Don't run pipelines from merge requests out of master (should always be redundant)
    - if: $CI_COMMIT_REF_NAME == "master" && $CI_MERGE_REQUEST_ID
      when: never
    # Otherwise, run the pipelines as defined below
    - when: always

# NOTE: the templates below are so that we can add additional jobs to the CI
#       pipeline for merge requests (MR). Ideally, anytime someone pushes to *any*
#       branch, we would just run basic static analysis, and then, when a MR is
#       opened, we'd add in building and deploying the python package to S3 and
#       the docker container to ECR so that reviewers can easily test the MR.
#       HOWEVER, gitlab's merge requests pipelines work differently than other
#       pipelines meaning we need to specify enable them for jobs we want to run:
#           https://docs.gitlab.com/12.10/ee/ci/merge_request_pipelines/index.html
#       But doing so creates both a "push" pipeline and a "MR" pipeline, so the
#       `always_run` jobs are run in duplicate. There doesn't seem to be any
#       easy way around this currently:
#           https://gitlab.com/gitlab-org/gitlab-foss/issues/56632
#      So, our team we'll have to live with duplicates for a bit, and follow
#      "only open a MR when you're ready for review!" best practice.
.always_run_template: &always_run
  rules:
    - if: $CI_MERGE_REQUEST_ID
      when: on_success
    - when: on_success

.mr_protected_template: &only_mr_protected
  rules:
    - if: $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master" || $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "develop"
      when: on_success
    - if: $CI_COMMIT_REF_PROTECTED == "true"
      when: on_success
    - when: never


default:
  image:
    name: continuumio/miniconda3:4.7.12
    entrypoint: ["/bin/bash"]
  before_script:
    - *before_defaults

stages:
    - tools-bot
    - trigger merge-back
    - static analysis
    - test
    - dependancy analysis
    - package
    - containerize
    - verify


tag version:
  stage: tools-bot
  before_script:
    - chmod 600 ${GITLAB_TOOLS_BOT_SSH}
    - git config core.sshCommand "ssh -o IdentitiesOnly=yes -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null
      -i ${GITLAB_TOOLS_BOT_SSH} -F /dev/null"
    - git config --global user.email "UAF-asf-apd@alaska.edu"
    - git config --global user.name "Tools-bot"
    - git remote set-url origin git@scm.asf.alaska.edu:hyp3/hyp3-geocode.git
    - git fetch --all
    - apt-get install -y jq curl
    - *before_defaults
    - python3 -m pip install bump2version
  script:
    - source .gitlab/tag_version.sh
  rules:
    - if: $CI_COMMIT_REF_NAME == "master" && $CI_MERGE_REQUEST_ID == null

master to develop:
  stage: trigger merge-back
  trigger:
    include: .gitlab/merge_back.gitlab-ci.yaml
  rules:
    - if: $CI_COMMIT_REF_NAME == "master" && $CI_MERGE_REQUEST_ID == null



xenon:
  stage: static analysis
  before_script:
    - *before_defaults
    - python3 -m pip install xenon radon
  script:
    - xenon -a B -m A -b A hyp3_geocode
  after_script:
    - radon cc -s -a -O radon_cc_report.txt hyp3_geocode
    - radon raw -s -O radon_raw_report.txt hyp3_geocode
    - radon mi -s -x F -O radon_mi_report.txt hyp3_geocode
    - radon hal -O radon_hal_report.txt hyp3_geocode
  allow_failure: true
  artifacts:
    when: on_failure
    paths:
      - radon_*_report.txt
  <<: *always_run


pytest 37:
  stage: test
  before_script:
    - *before_conda_env
  script:
    - tox --develop -e py37 -- --cov=hyp3_geocode
  coverage: '/TOTAL\s+\d+\s+\d+\s+(\d+%)/'
  artifacts:
    paths:
      - pip_freeze_*.txt
      - conda_export_*.txt
  <<: *always_run

safety 37:
  stage: dependancy analysis
  before_script:
    - *before_defaults
    - python3 -m pip install safety
  script:
    - safety check --full-report --stdin < pip_freeze_py37.txt
    - awk -F '=' '/^[^#]/ {print $1 "==" $2}' conda_export_py37.txt | safety check --full-report --stdin
  needs:
    - job: "pytest 37"
      artifacts: true
  <<: *always_run


package S3 PyPI:
  stage: package
  script:
    - echo "Building version $(python3 setup.py --version)"
    - python3 setup.py sdist bdist_wheel
    - echo "Uploading version $(python3 setup.py --version) to S3-PyPI"
    - s3pypi --bucket hyp3-pypi --force --verbose
  <<: *only_mr_protected


dockerize:
  stage: containerize
  tags:
    - docker
    - apd-dev
  before_script:
    - python3 -m pip install --user "setuptools>=42" wheel "setuptools-scm[toml]>=3.4"
    - export SDIST_VERSION=$(python3 setup.py --version)
    - export CI_JOB_TIMESTAMP=$(date --utc --rfc-3339=seconds)
    - aws s3 cp s3://hyp3-docker/software/GAMMA_SOFTWARE-20191203_MSP_ISP_DIFF_LAT.linux64_ubuntu1804.tar.gz .
    - tar -zxvf GAMMA_SOFTWARE-20191203_MSP_ISP_DIFF_LAT.linux64_ubuntu1804.tar.gz
  script:
    - docker build --no-cache
      -t ${HYP3_REGISTRY}/hyp3-geocode:${SDIST_VERSION/+/_}
      --label org.opencontainers.image.created="${CI_JOB_TIMESTAMP}"
      --label org.opencontainers.image.version="${SDIST_VERSION}"
      --label org.opencontainers.image.revision="${CI_COMMIT_SHORT_SHA}"
      --build-arg S3_PYPI_HOST=${S3_PYPI_HOST}
      --build-arg SDIST_SPEC="==${SDIST_VERSION}" .
    - aws ecr get-login-password | docker login --username AWS --password-stdin ${HYP3_REGISTRY}
    - docker push ${HYP3_REGISTRY}/hyp3-geocode:${SDIST_VERSION/+/_}
  <<: *only_mr_protected


verify dockerize (test):
  stage: verify
  tags:
    - docker
    - apd-dev
  before_script:
    - python3 -m pip install --user "setuptools>=42" wheel "setuptools-scm[toml]>=3.4"
    - export SDIST_VERSION=$(python3 setup.py --version)
  script:
    - docker tag ${HYP3_REGISTRY}/hyp3-geocode:${SDIST_VERSION/+/_}
      ${HYP3_REGISTRY}/hyp3-geocode:test
    - aws ecr get-login-password | docker login --username AWS --password-stdin ${HYP3_REGISTRY}
    - docker push ${HYP3_REGISTRY}/hyp3-geocode:test
  needs:
    - job: "dockerize"
      artifacts: true
  rules:
    - if: $CI_COMMIT_REF_NAME == "develop"

verify dockerize:
  stage: verify
  tags:
    - docker
    - apd-dev
  before_script:
    - python3 -m pip install --user "setuptools>=42" wheel "setuptools-scm[toml]>=3.4"
    - export SDIST_VERSION=$(python3 setup.py --version)
  script:
    - docker tag ${HYP3_REGISTRY}/hyp3-geocode:${SDIST_VERSION/+/_}
      ${HYP3_REGISTRY}/hyp3-geocode:latest
    - aws ecr get-login-password | docker login --username AWS --password-stdin ${HYP3_REGISTRY}
    - docker push ${HYP3_REGISTRY}/hyp3-geocode:latest
  needs:
    - job: "dockerize"
      artifacts: true
  rules:
    - if: $CI_COMMIT_REF_NAME == "master"
